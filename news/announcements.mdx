---
title: 'Announcements'
description: 'Latest news and announcements from the MCPBench team'
---

# MCPBench Announcements

Stay up to date with the latest news, updates, and announcements from the MCPBench team.

## Latest News

<CardGroup cols={1}>
  <Card title="MCPBench v2.0 Released - Major Update with 50+ New Tasks" icon="star">
    **Date**: December 15, 2024  
    **Author**: Nicholas Carlini  
    
    We're excited to announce the release of MCPBench v2.0, featuring 50+ new benchmark tasks across all categories. This major update includes enhanced evaluation metrics, improved automation, and expanded coverage of real-world terminal operations.
    
    **Key Features:**
    - 50+ new benchmark tasks
    - Enhanced evaluation framework
    - Improved leaderboard with detailed metrics
    - Better documentation and tutorials
    
    [Read more about v2.0 features →](/news/releases/v2-0-release-notes)
  </Card>
  
  <Card title="Stanford x Laude Collaboration Announced" icon="handshake">
    **Date**: December 10, 2024  
    **Author**: jeffreywpli  
    
    We're thrilled to announce a new collaboration between Stanford University and Laude to advance AI agent evaluation research. This partnership will focus on developing more sophisticated evaluation methods and expanding our benchmark coverage.
    
    **Partnership Goals:**
    - Advanced evaluation methodologies
    - Expanded task coverage
    - Research collaboration
    - Academic publications
    
    [Learn more about the collaboration →](/news/updates/stanford-laude-collaboration)
  </Card>
  
  <Card title="New Security Task Category Added" icon="shield">
    **Date**: December 8, 2024  
    **Author**: Jan-Lucas Uslu  
    
    We've added a comprehensive security task category with 28 new challenges covering penetration testing, cryptography, and security auditing. These tasks are designed to evaluate AI agents' capabilities in security-related terminal operations.
    
    **New Tasks Include:**
    - Password cracking challenges
    - Network security assessments
    - Cryptographic operations
    - Security audit procedures
    
    [Explore security tasks →](/tasks/security)
  </Card>
  
  <Card title="Community Milestone: 1000+ GitHub Stars" icon="github">
    **Date**: December 5, 2024  
    **Author**: MCPBench Team  
    
    Thank you to our amazing community! We've reached 1000+ GitHub stars, reflecting the growing interest in AI agent evaluation and the value of our benchmark. This milestone wouldn't be possible without our contributors and users.
    
    **Community Stats:**
    - 1000+ GitHub stars
    - 200+ Discord members
    - 50+ contributors
    - 127 benchmark tasks
    
    [Join our community →](https://discord.gg/mcpbench)
  </Card>
</CardGroup>

## Upcoming Events

<CardGroup cols={2}>
  <Card title="Weekly Office Hours" icon="calendar">
    **When**: Every Tuesday, 2-3 PM PST  
    **Where**: Discord Voice Channel  
    **Topic**: General Q&A and contribution help
  </Card>
  <Card title="Task Creation Workshop" icon="users">
    **When**: December 20, 2024, 10 AM PST  
    **Where**: Discord + Zoom  
    **Topic**: Learn how to create high-quality benchmark tasks
  </Card>
  <Card title="Research Paper Presentation" icon="presentation">
    **When**: January 15, 2025, 1 PM PST  
    **Where**: Virtual Conference  
    **Topic**: "Evaluating AI Agents in Terminal Environments"
  </Card>
  <Card title="Community Meetup" icon="coffee">
    **When**: February 1, 2025, 6 PM PST  
    **Where**: San Francisco, CA  
    **Topic**: In-person networking and collaboration
  </Card>
</CardGroup>

## Recent Updates

<CardGroup cols={2}>
  <Card title="Leaderboard Enhancement" icon="trophy">
    **Date**: December 12, 2024  
    Added detailed performance metrics by category and improved visualization.
  </Card>
  <Card title="Documentation Overhaul" icon="book">
    **Date**: December 10, 2024  
    Complete rewrite of getting started guides and API documentation.
  </Card>
  <Card title="Automated Testing" icon="check-circle">
    **Date**: December 8, 2024  
    Implemented comprehensive automated testing for all benchmark tasks.
  </Card>
  <Card title="Performance Improvements" icon="zap">
    **Date**: December 5, 2024  
    Optimized evaluation framework for faster task execution.
  </Card>
</CardGroup>

## Research Highlights

<CardGroup cols={1}>
  <Card title="Paper Accepted: 'Benchmarking AI Agents in Terminal Environments'" icon="book">
    **Date**: December 1, 2024  
    **Authors**: Nicholas Carlini, jeffreywpli, et al.  
    **Venue**: NeurIPS 2024 Workshop on AI Agents  
    
    Our research paper on MCPBench has been accepted for presentation at the NeurIPS 2024 Workshop on AI Agents. The paper presents our evaluation methodology and initial results from testing various AI models on our benchmark.
    
    [Read the paper →](/research/papers/neurips-2024)
  </Card>
</CardGroup>

## Community Spotlight

<CardGroup cols={2}>
  <Card title="Contributor of the Month: Alex Chen" icon="award">
    **December 2024**  
    Created 5 new system administration tasks and helped improve our evaluation infrastructure.
  </Card>
  <Card title="Community Champion: Maria Rodriguez" icon="star">
    **November 2024**  
    Actively helps new contributors and maintains our Discord community.
  </Card>
</CardGroup>

## Stay Connected

<CardGroup cols={3}>
  <Card title="GitHub" icon="github" href="https://github.com/mcpbench">
    Follow us on GitHub for code updates and issue tracking.
  </Card>
  <Card title="Discord" icon="message-circle" href="https://discord.gg/mcpbench">
    Join our Discord community for real-time discussions.
  </Card>
  <Card title="Twitter" icon="twitter" href="https://twitter.com/mcpbench">
    Follow us on Twitter for quick updates and announcements.
  </Card>
</CardGroup>

<Info>
  **Subscribe to Updates**: Join our Discord server to get notified about new announcements and updates in real-time.
</Info>
